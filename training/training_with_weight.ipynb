{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "179092b4",
   "metadata": {},
   "source": [
    "Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27d8544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aa862b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 8\n",
    "CHANNELS = 3\n",
    "EPOCHS = 25\n",
    "DIR_NAME = \"datasets/PlantVillage/Split/\" \n",
    "N_CLASSES = 10\n",
    "\n",
    "TRAIN_DIR = DIR_NAME + \"train/\"\n",
    "VAL_DIR = DIR_NAME + \"val/\"\n",
    "TEST_DIR = DIR_NAME + \"test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "962e5a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 10 classes.\n",
      "Found 100 images belonging to 10 classes.\n",
      "Found 100 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# create a data generator\n",
    "datagen = ImageDataGenerator()\n",
    "\n",
    "train_it = datagen.flow_from_directory(TRAIN_DIR, batch_size=799)\n",
    "\n",
    "val_it = datagen.flow_from_directory(VAL_DIR, batch_size=99)\n",
    "\n",
    "test_it = datagen.flow_from_directory(TEST_DIR, batch_size=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e42217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_it.next()\n",
    "X_test, y_test = test_it.next()\n",
    "X_val, y_val = val_it.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58a81362",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (train_it.batch_index - 1) * train_it.batch_size\n",
    "fname = train_it.filenames[idx : idx + train_it.batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cda94c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = None\n",
    "with open('weights.csv', 'r') as file:\n",
    "    weights = dict(line.strip().split(',') for line in file.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13cd0788",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = []\n",
    "for f in fname:\n",
    "  basename = f.split('\\\\')[-1]\n",
    "  if basename in weights:\n",
    "    sample_weights.append(float(weights[basename]))\n",
    "  else:\n",
    "    sample_weights.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c95f0872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799\n"
     ]
    }
   ],
   "source": [
    "print(len(sample_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d6ddc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train, sample_weights)).batch(1)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(1)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ec15ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names = dataset.class_names\n",
    "# print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e5a2903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size =  799\n",
      "Validation Size =  99\n",
      "Testing Size =  99\n"
     ]
    }
   ],
   "source": [
    "# train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset, 0.8, 0.1, 0.1, False)\n",
    "print(\"Training Size = \", len(train_dataset))\n",
    "print(\"Validation Size = \", len(val_dataset))\n",
    "print(\"Testing Size = \", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd368079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache the images, using tf prefetch pipeline\n",
    "train_ds = train_dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds = test_dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cac19fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_and_rescale = tf.keras.Sequential([\n",
    "    layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    layers.Rescaling(1.0/255)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfeb95ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF data argumentation: fix contrast, rotation of images by transformation\n",
    "data_argumentaion = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1094a914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "# Convolutional layer = Conv2D\n",
    "input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "\n",
    "model = Sequential([\n",
    "    resize_and_rescale,\n",
    "    data_argumentaion,\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(N_CLASSES, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.build(input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "139d7abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (8, 256, 256, 3)          0         \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 246016)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                15745088  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,765,130\n",
      "Trainable params: 15,765,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aeec278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    # loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    # run_eagerly=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4097ca13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "799/799 [==============================] - 233s 286ms/step - loss: 3.4832e-04 - accuracy: 0.1076 - val_loss: 0.3334 - val_accuracy: 0.1010\n",
      "Epoch 2/25\n",
      "799/799 [==============================] - 248s 310ms/step - loss: 3.2351e-04 - accuracy: 0.1464 - val_loss: 0.3221 - val_accuracy: 0.2121\n",
      "Epoch 3/25\n",
      "799/799 [==============================] - 262s 328ms/step - loss: 2.9777e-04 - accuracy: 0.2466 - val_loss: 0.2842 - val_accuracy: 0.2828\n",
      "Epoch 4/25\n",
      "799/799 [==============================] - 229s 287ms/step - loss: 2.7532e-04 - accuracy: 0.3292 - val_loss: 0.2630 - val_accuracy: 0.3636\n",
      "Epoch 5/25\n",
      "799/799 [==============================] - 249s 312ms/step - loss: 2.6180e-04 - accuracy: 0.3830 - val_loss: 0.2669 - val_accuracy: 0.3838\n",
      "Epoch 6/25\n",
      "799/799 [==============================] - 248s 310ms/step - loss: 2.5643e-04 - accuracy: 0.4155 - val_loss: 0.2631 - val_accuracy: 0.3535\n",
      "Epoch 7/25\n",
      "799/799 [==============================] - 241s 301ms/step - loss: 2.3777e-04 - accuracy: 0.4693 - val_loss: 0.2668 - val_accuracy: 0.4242\n",
      "Epoch 8/25\n",
      "799/799 [==============================] - 244s 306ms/step - loss: 2.2481e-04 - accuracy: 0.5219 - val_loss: 0.2633 - val_accuracy: 0.4242\n",
      "Epoch 9/25\n",
      "799/799 [==============================] - 242s 303ms/step - loss: 2.1227e-04 - accuracy: 0.5494 - val_loss: 0.2474 - val_accuracy: 0.4646\n",
      "Epoch 10/25\n",
      "799/799 [==============================] - 247s 309ms/step - loss: 1.9733e-04 - accuracy: 0.6133 - val_loss: 0.2582 - val_accuracy: 0.4141\n",
      "Epoch 11/25\n",
      "799/799 [==============================] - 248s 311ms/step - loss: 1.8497e-04 - accuracy: 0.6183 - val_loss: 0.2452 - val_accuracy: 0.5253\n",
      "Epoch 12/25\n",
      "479/799 [================>.............] - ETA: 1:35 - loss: 1.8422e-04 - accuracy: 0.6096"
     ]
    }
   ],
   "source": [
    "# history = model.fit(\n",
    "#     train_ds,\n",
    "#     epochs=EPOCHS,\n",
    "#     verbose=1,\n",
    "#     validation_data=val_ds\n",
    "# )\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    "    validation_data=val_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdf3439",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fa04da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history.params\n",
    "# history.history['accuracy']\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ae0949",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(range(EPOCHS),acc, label='Training Accuracy')\n",
    "plt.plot(range(EPOCHS), val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(EPOCHS),loss, label='Training Loss')\n",
    "plt.plot(range(EPOCHS), val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab9748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make Predictions\n",
    "# '''\n",
    "# for images_batch, labels_batch in test_ds.take(1):\n",
    "#     first_image = images_batch[0].numpy().astype('uint8')\n",
    "#     first_label = labels_batch[0]\n",
    "    \n",
    "#     print(\"First image to predict\")\n",
    "#     plt.imshow(first_image)\n",
    "#     print(\"actual label:\", class_names[first_label])\n",
    "    \n",
    "#     batch_prediction = model.predict(images_batch)\n",
    "#     predicted_class_index = np.argmax(batch_prediction[0])\n",
    "#     print(\"Predicted label: \", class_names[predicted_class_index])\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd96a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, img):\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
    "    img_array = tf.expand_dims(img_array, 0)  #creating a batch\n",
    "    \n",
    "    predictions = model.predict(img_array)\n",
    "    \n",
    "    predicted_class =  class_names[np.argmax(predictions[0])]\n",
    "    confidence = round(100*(np.max(predictions[0])),2)\n",
    "    return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b48d4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,14))\n",
    "for images, labels in test_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3,3,i+1)\n",
    "        plt.imshow(images[i].numpy().astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        \n",
    "        predicted_class, confidence = predict(model, images[i].numpy())\n",
    "        \n",
    "        actual_class = class_names[labels[i]]\n",
    "        \n",
    "        plt.title(f\"Actual: {actual_class},\\nPredicted: {predicted_class}.\\nConfidence: {confidence}%\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0048386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model_version=1\n",
    "model.save(f\"../models/{model_version}\",save_format='h5')\n",
    "# model.save(\"../models/model1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "5ff5ac61870afef2f92de208f8d497b668dbb82d4efec62ea5e0e67a445f7300"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
